# Deploying Aethercast to Google Cloud Platform (GCP)

## 1. Introduction

This guide provides instructions and considerations for deploying the Aethercast system to Google Cloud Platform (GCP). Aethercast is a multi-service application, and deploying it effectively involves leveraging several GCP services.
We will primarily focus on using:
-   **Cloud Run:** For running our containerized microservices in a serverless environment.
-   **Cloud SQL for PostgreSQL:** As a managed relational database for services like CPOA and API Gateway.
-   **Google Cloud Storage (GCS):** For storing media assets (audio, images) generated by AIMS_TTS and IGA.
-   **Vertex AI:** For accessing the AI models used by AIMS, AIMS_TTS, and IGA.
-   **Artifact Registry:** For storing and managing Docker container images.
-   **Secret Manager:** For securely storing sensitive configurations like API keys and database passwords.

## 2. Prerequisites

Before you begin, ensure you have the following:

-   **Google Cloud Platform (GCP) Account:** An active GCP account with billing enabled. If you are new to GCP, you might be eligible for a free trial.
-   **`gcloud` Command-Line Tool:** The Google Cloud SDK installed and configured on your local machine.
    -   Authenticate with your GCP account: `gcloud auth login`
    -   Set your default project: `gcloud config set project YOUR_PROJECT_ID`
    -   Ensure components are up-to-date: `gcloud components update`
-   **Docker Desktop:** Installed locally. This is necessary for building and testing container images before pushing them to a GCP registry.
-   **Git:** Installed on your local machine, and the Aethercast source code cloned:
    ```bash
    git clone <repository_url>
    cd aethercast
    ```

## 3. Core GCP Setup

This section details the initial Google Cloud Platform project configuration, enabling essential APIs, and setting up a Google Cloud Storage bucket for Aethercast. Many of these foundational steps are also outlined in the 'GCP Prerequisites and Setup for Local Development' section of the main project `README.md`, which should be reviewed for context, especially regarding API needs for local development.

### 3.1. GCP Project Setup

A GCP project is the foundational organizational unit where you create, manage, and use Google Cloud resources.

1.  **Create or Select a Project:**
    *   **New Project:** If you don't have an existing project for Aethercast, create one:
        *   **Via GCP Console:** Navigate to the [Project Selector page](https://console.cloud.google.com/projectselector2/home/dashboard) and click "Create Project". Provide a project name and organization/location if applicable.
        *   **Via `gcloud` CLI:**
            ```bash
            gcloud projects create YOUR_PROJECT_ID --name="Aethercast Deployment"
            ```
            Replace `YOUR_PROJECT_ID` with a globally unique ID for your project.
    *   **Existing Project:** If you have a suitable existing project, you can use that. Note its Project ID.

2.  **Set Project for `gcloud` CLI:**
    Ensure your local `gcloud` tool is configured to use your chosen project:
    ```bash
    gcloud config set project YOUR_PROJECT_ID
    ```
    Replace `YOUR_PROJECT_ID` with the ID of the project you will be using.

3.  **Link Billing Account:**
    If you created a new project, ensure it's linked to an active billing account. Resources like Cloud SQL, Cloud Run (beyond free tier), and Vertex AI require billing.
    *   You can do this via the [Billing section](https://console.cloud.google.com/billing) in the GCP Console. A project must have a billing account to enable most APIs and deploy services.

### 3.2. Enable APIs

Google Cloud services are accessed via APIs, which must be enabled for your project before they can be used.

**Why APIs need to be enabled:** Enabling an API associates it with your current project, allows you to monitor its usage, and includes it in your project's billing.

**Required APIs for Aethercast deployment:**

*   **Vertex AI API (`aiplatform.googleapis.com`):** For AIMS, AIMS_TTS, and IGA services.
*   **Cloud Storage API (`storage.googleapis.com`):** For GCS bucket creation and access (used by AIMS_TTS, IGA, API Gateway).
*   **Cloud Run Admin API (`run.googleapis.com`):** To deploy and manage containerized applications.
*   **Cloud SQL Admin API (`sqladmin.googleapis.com`):** To create and manage PostgreSQL instances.
*   **Artifact Registry API (`artifactregistry.googleapis.com`):** To store and manage Docker images.
*   **Cloud Build API (`cloudbuild.googleapis.com`):** (Optional, but recommended for CI/CD) To build container images automatically.
*   **Secret Manager API (`secretmanager.googleapis.com`):** To store and manage sensitive secrets like API keys and passwords.
*   **Identity and Access Management (IAM) API (`iam.googleapis.com`):** To manage permissions and service accounts.

**Enabling APIs:**

*   **Via GCP Console:**
    1.  Go to the [API Library](https://console.cloud.google.com/apis/library) in the GCP Console.
    2.  Search for each API listed above by its name or service name (e.g., `aiplatform.googleapis.com`).
    3.  Select the API and click "Enable".
*   **Via `gcloud` CLI:**
    You can enable all required APIs with a single command:
    ```bash
    gcloud services enable \
        aiplatform.googleapis.com \
        storage.googleapis.com \
        run.googleapis.com \
        sqladmin.googleapis.com \
        artifactregistry.googleapis.com \
        cloudbuild.googleapis.com \
        secretmanager.googleapis.com \
        iam.googleapis.com
    ```

### 3.3. Google Cloud Storage (GCS) Bucket

A GCS bucket is required for storing generated media files, such as podcast audio from AIMS_TTS and cover images from IGA.

**Purpose:**
-   Persistent storage for audio files (`.mp3`, `.ogg`, etc.).
-   Persistent storage for image files (`.png`, `.jpg`, etc.).
-   Serving these files to users via signed URLs or public access (if configured).

**Basic Bucket Creation:**
Refer to the main `README.md`'s section on 'GCP Prerequisites and Setup for Local Development' for the fundamental steps to create a GCS bucket.

**GCP Deployment Specific Considerations:**

*   **Globally Unique Name:** Choose a globally unique name for your bucket. It's good practice to include your project ID or a unique identifier.
    -   Example: `aethercast-media-YOUR_PROJECT_ID` or `aethercast-assets-randomuuid`
*   **Region:** Select a region for your bucket. For optimal performance and to minimize cross-region data transfer costs, choose the same region where you plan to deploy your Cloud Run services and run Vertex AI jobs (e.g., `us-central1`, `europe-west1`).
*   **Storage Class:** For most Aethercast use cases, the "Standard" storage class is appropriate for frequently accessed media.
*   **Access Control:** Select "Uniform" for bucket-level access control. This is simpler to manage with IAM permissions.
*   **Creation (example using `gcloud`):**
    ```bash
    gcloud storage buckets create gs://YOUR_UNIQUE_BUCKET_NAME --project=YOUR_PROJECT_ID --location=YOUR_CHOSEN_REGION --uniform-bucket-level-access
    ```
    Replace placeholders with your actual values.

**Environment Variable:**
The services that interact with GCS (AIMS_TTS, IGA, API Gateway) will need the `GCS_BUCKET_NAME` environment variable set to this bucket's name (e.g., `your-aethercast-media-bucket-name`). This will be configured during their deployment to Cloud Run.

**Permissions:**
Specific IAM permissions allowing Cloud Run services (via their service accounts) to read from and write to this bucket will be detailed in a later section covering service account configuration and Cloud Run deployment.

## 4. Database Setup (Cloud SQL for PostgreSQL)

Aethercast uses a PostgreSQL database to store persistent information such as podcast task states (managed by CPOA), user accounts and sessions (managed by the API Gateway), cached scripts, discovered topics, and generated snippets. For a robust and scalable deployment on GCP, using Cloud SQL for PostgreSQL is recommended.

### 4.1. Create Cloud SQL for PostgreSQL Instance

You can create a Cloud SQL for PostgreSQL instance using either the GCP Console or the `gcloud` command-line tool.

**Key Configuration Choices:**

*   **Instance ID:** A unique name for your instance (e.g., `aethercast-postgres-instance`).
*   **Password (`postgres` user):** During creation, you'll set a password for the default `postgres` superuser. **Generate a strong, unique password and save it securely.** This password will be needed for initial database setup. We will later store application-specific passwords in Secret Manager.
*   **Database Version:** Choose a recent version of PostgreSQL (e.g., PostgreSQL 13, 14, or 15+).
*   **Region and Zone:** Select the same region where you plan to deploy your Cloud Run services and other GCP resources to minimize latency and cost. You can choose a specific zone or let GCP choose one for you.
*   **Instance Sizing:**
    *   **Machine Type (vCPUs, Memory):** Start with a smaller instance size for development and testing (e.g., `db-f1-micro` or `db-g1-small`). You can scale this up later as needed.
    *   **Storage Type and Capacity:** SSD is recommended for performance. Start with a reasonable capacity (e.g., 10GB or 20GB) and enable automatic storage increases if desired.
*   **Connectivity:**
    *   **Public IP vs. Private IP:**
        *   **Private IP (Recommended for Production):** Assigns the instance an internal IP address within a VPC network. This is more secure as the database is not exposed to the public internet. Requires Cloud Run services to connect via the same VPC network, often using a Serverless VPC Access connector.
        *   **Public IP:** Assigns a public IP address. Access can be restricted using authorized networks, but Private IP is generally preferred for backend services.
    *   If you choose **Private IP**, you will need to have a VPC network configured. Details on setting up a Serverless VPC Access connector for Cloud Run services will be covered in later sections.
*   **Backups and Point-in-Time Recovery (PITR):** For production environments, enable automated backups and PITR to protect against data loss.

**Steps (using GCP Console - recommended for initial setup):**

1.  Navigate to [Cloud SQL Instances](https://console.cloud.google.com/sql/instances) in the GCP Console.
2.  Click "Create Instance".
3.  Choose "Choose PostgreSQL".
4.  Enter an **Instance ID** (e.g., `aethercast-postgres-instance`).
5.  Enter a strong **Password** for the `postgres` user. Store this securely.
6.  Select the desired **Database version**, **Region**, and **Zone**.
7.  Under "Customize your instance" > "Machine type and storage", select an appropriate size. Start small for development.
8.  Under "Customize your instance" > "Connections":
    *   If opting for **Private IP**:
        *   Ensure "Private IP" is selected.
        *   Select the VPC **Network**. If you don't have one, the "default" network might exist, or you may need to create one first (outside the scope of this immediate step, but necessary).
        *   An IP range will be allocated, or you can configure one.
    *   If opting for **Public IP** (less recommended for production):
        *   Ensure "Public IP" is selected.
        *   Later, you would configure "Authorized networks" to restrict access.
9.  Review other settings like Backups and Maintenance.
10. Click "Create". Instance creation may take several minutes.

**Steps (example using `gcloud` - for Private IP):**

```bash
gcloud sql instances create aethercast-postgres-instance \
    --database-version=POSTGRES_15 \
    --cpu=1 \
    --memory=3840MB \
    --region=YOUR_CHOSEN_REGION \
    --storage-size=10GB \
    --storage-type=SSD \
    --network=projects/YOUR_PROJECT_ID/global/networks/YOUR_VPC_NETWORK_NAME \
    --no-assign-ip # This flag ensures only a private IP is assigned
    # For public IP, you would use --assign-ip and configure --authorized-networks
```
*Remember to replace placeholders. You'll be prompted to set the `postgres` user password.*

### 4.2. Create Database and User

Once the Cloud SQL instance is running, you need to connect to it and create the specific database and user for Aethercast.

**Connecting to the Instance:**

*   **Using Cloud SQL Auth Proxy (Recommended for local connections):**
    1.  [Install the Cloud SQL Auth Proxy](https://cloud.google.com/sql/docs/postgres/connect-auth-proxy).
    2.  Get your instance connection name from the Cloud SQL instance details page in the console (e.g., `YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance`).
    3.  Run the proxy: `./cloud_sql_proxy -instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance=tcp:5432`
    4.  In a new terminal, connect using `psql`:
        ```bash
        psql "host=127.0.0.1 port=5432 sslmode=disable user=postgres dbname=postgres"
        ```
        Enter the `postgres` user password you set during instance creation.
*   **Using `gcloud sql connect`:**
    ```bash
    gcloud sql connect aethercast-postgres-instance --user=postgres
    ```
    Enter the `postgres` user password.

**SQL Commands:**

Execute the following SQL commands in your `psql` session:

1.  **Create the database:**
    ```sql
    CREATE DATABASE aethercast_db;
    ```
2.  **Create the application user:**
    Choose a strong, unique password for `aethercastuser`. This password will be stored in Secret Manager later.
    ```sql
    CREATE USER aethercastuser WITH PASSWORD 'YOUR_CHOSEN_SECURE_PASSWORD_FOR_APPUSER';
    ```
3.  **Grant privileges to the user for the database:**
    ```sql
    GRANT ALL PRIVILEGES ON DATABASE aethercast_db TO aethercastuser;
    ```
4.  **Set default privileges for future objects created by `aethercastuser` or other users (optional but good practice):**
    Connect to the `aethercast_db` first: `\c aethercast_db`
    Then run:
    ```sql
    ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON TABLES TO aethercastuser;
    ALTER DEFAULT PRIVILEGES IN SCHEMA public GRANT ALL ON SEQUENCES TO aethercastuser;
    ```
    You might also need to grant usage on the public schema if not already default: `GRANT USAGE ON SCHEMA public TO aethercastuser;`

5.  **Apply Core Table Migrations:**
    After the database and user are created, and you are connected to `aethercast_db` as `aethercastuser` (or `postgres` user if `aethercastuser` doesn't have rights to create tables initially, then `GRANT ALL ON TABLE ... TO aethercastuser;`):
    *   **Idempotency Table:** Apply the migration script for the shared `idempotency_keys` table:
        ```sql
        -- Contents of aethercast/data_stores/migrations/001_create_idempotency_keys_table.sql
        CREATE TABLE IF NOT EXISTS idempotency_keys (
            idempotency_key TEXT PRIMARY KEY,
            task_name TEXT NOT NULL,
            workflow_id TEXT,
            created_at TIMESTAMPTZ NOT NULL DEFAULT current_timestamp,
            locked_at TIMESTAMPTZ,
            status TEXT NOT NULL, -- e.g., 'processing', 'completed', 'failed'
            result_payload JSONB,
            error_payload JSONB
        );
        CREATE INDEX IF NOT EXISTS idx_idempotency_locked_at ON idempotency_keys (locked_at) WHERE locked_at IS NOT NULL;
        CREATE INDEX IF NOT EXISTS idx_idempotency_status ON idempotency_keys (status);
        ```
    *   Other services like TDA (`init_tda_db()`) and API Gateway (`init_db()`) create their own tables on startup if they don't exist. Ensure the `aethercastuser` has permissions to create tables or run these DDL statements manually.

### 4.3. Database Connection Details for Services

The Aethercast services deployed to Cloud Run will need the following connection details. These should be stored securely (e.g., in Secret Manager) and provided to the services as environment variables.

*   `DATABASE_TYPE="postgres"` (This is usually already set in the `.env.example` files for services that use the DB).
*   `POSTGRES_USER="aethercastuser"`
*   `POSTGRES_PASSWORD="YOUR_CHOSEN_SECURE_PASSWORD_FOR_APPUSER"` (The one you just set for `aethercastuser`).
*   `POSTGRES_DB="aethercast_db"`
*   `POSTGRES_HOST`: This depends on the connection method:
    *   **Cloud SQL Auth Proxy (Recommended for Cloud Run):** When Cloud Run services connect using the built-in Cloud SQL Auth Proxy integration, the host string is typically a Unix socket path provided by Cloud Run: `/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance`.
    *   **Private IP:** If Cloud Run services connect directly via Private IP (requiring a Serverless VPC Access connector), `POSTGRES_HOST` will be the private IP address of your Cloud SQL instance (e.g., `10.x.x.x`).
*   `POSTGRES_PORT="5432"` (Standard PostgreSQL port).

**Connection Methods for Cloud Run:**

1.  **Cloud SQL Auth Proxy (Recommended):**
    *   Cloud Run has built-in support for connecting to Cloud SQL instances securely using the Cloud SQL Auth Proxy.
    *   When configuring your Cloud Run service, you specify the Cloud SQL instance connection. Cloud Run then makes a secure Unix socket available to your container at a path like `/cloudsql/PROJECT_ID:REGION:INSTANCE_ID`.
    *   Your application's database library connects to this socket. For many Python libraries (like `psycopg2`), setting `POSTGRES_HOST` to this socket path works directly.
    *   This method handles authentication and encryption automatically without needing to manage SSL certificates or IP allowlisting for the Cloud Run instances.

2.  **Private IP Address:**
    *   Requires your Cloud Run service to be associated with a Serverless VPC Access connector that can reach the VPC network where your Cloud SQL instance resides.
    *   `POSTGRES_HOST` would be the internal IP address of the Cloud SQL instance.
    *   This provides network isolation but involves managing the VPC connector.

Managing and injecting these connection details (especially the password) securely into your Cloud Run services using Secret Manager will be covered in **Section 5. Secret Management**.

## 5. Secret Management (Google Secret Manager)

It is critical to securely manage sensitive data such as API keys, database passwords, and application-specific secret keys. Hardcoding these values into source code or placing them directly as plain text environment variables in service definitions is insecure and not recommended. Google Cloud Secret Manager provides a centralized and secure way to store, manage, and access these secrets.

### 5.1. Storing Secrets in Secret Manager

You will create entries in Secret Manager for each piece of sensitive information your Aethercast services need.

**Creating Secrets:**

You can create secrets using the GCP Console or the `gcloud` command-line tool.

*   **Via GCP Console:**
    1.  Navigate to [Secret Manager](https://console.cloud.google.com/security/secret-manager) in the GCP Console.
    2.  Click "Create Secret".
    3.  Enter a **Name** for the secret (e.g., `aethercast-db-password`). Use a consistent naming convention.
    4.  Enter the **Secret value** (e.g., the strong password you generated for `aethercastuser`).
    5.  Leave other settings as default for now (replication policy, etc.) unless you have specific needs.
    6.  Click "Create Secret".

*   **Via `gcloud` CLI:**
    ```bash
    echo "YOUR_SECRET_VALUE" | gcloud secrets create SECRET_NAME --data-file=- --replication-policy=automatic
    ```
    Replace `YOUR_SECRET_VALUE` with the actual secret and `SECRET_NAME` with the name you want to give the secret in Secret Manager.
    Example:
    ```bash
    echo "s3cr3tP@ssword!" | gcloud secrets create aethercast-db-password --data-file=- --replication-policy=automatic
    ```

**Recommended Secrets for Aethercast:**

Create secrets for the following (use descriptive names):

*   **`aethercast-flask-secret-key`**: A strong, random string for `FLASK_SECRET_KEY` used by the API Gateway (and potentially other Flask-based services if they use sessions or need signing capabilities).
*   **`aethercast-db-password`**: The password you created for the `aethercastuser` PostgreSQL user (from Section 4.2).
*   **`aethercast-tda-news-api-key`**: The API key for NewsAPI, if you are using the real API for the Topic Discovery Agent (TDA).
*   **`aethercast-gcp-project-id`**: The value of your GCP Project ID. While not strictly a "secret", storing it here allows consistent injection into services.
*   **`aethercast-gcp-location`**: The primary GCP location you are using (e.g., `us-central1`).
*   **`aethercast-gcs-bucket-name`**: The name of your GCS bucket for media assets.

*   **Regarding `gcp-credentials.json`:**
    For services running on Cloud Run, the best practice is to use **Workload Identity** by assigning a dedicated IAM Service Account to each Cloud Run service, granting it the necessary permissions. This avoids needing to manage and mount service account key files (`gcp-credentials.json`) directly for GCP service access.
    Therefore, storing the entire `gcp-credentials.json` content as a secret is generally **not recommended** for Cloud Run deployments interfacing with other GCP services.

**Recommended Secrets for Aethercast (beyond those managed by Workload Identity for GCP services):**

*   **`aethercast-flask-secret-key`**: For `FLASK_SECRET_KEY` (API Gateway, other Flask apps).
*   **PostgreSQL Connection:**
    *   `aethercast-pg-user`: The application username (e.g., `aethercastuser`).
    *   `aethercast-pg-password`: The password for `aethercastuser`.
    *   `aethercast-pg-db`: The database name (e.g., `aethercast_db`).
    *   `aethercast-pg-host`: The Cloud SQL instance connection name (socket path like `/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance`) or private IP. This might be composed in the Cloud Run service definition if the socket path is predictable, or the IP stored if static.
    *   `aethercast-pg-port`: The database port (e.g., `5432`).
*   **Celery Broker/Backend URLs (if they contain sensitive parts):**
    *   `aethercast-celery-broker-url`: Full URL for Redis or other broker, if it includes a password.
    *   `aethercast-celery-result-backend-url`: Full URL for Redis or other backend, if sensitive.
*   **External API Keys:**
    *   `aethercast-tda-news-api-key`: For TDA's NewsAPI access.
*   **Shared Configuration Values (Optional, for consistency):**
    *   `aethercast-gcp-project-id`: Your GCP Project ID.
    *   `aethercast-gcp-location`: Primary GCP region.
    *   `aethercast-gcs-bucket-name`: GCS bucket name.

**Secret Versions:**
(As before)

### 5.2. Granting Access to Secrets

For a Cloud Run service to read a secret from Secret Manager, its underlying IAM service account must be granted permission to access that specific secret.

*   **Role:** The "Secret Manager Secret Accessor" role (`roles/secretmanager.secretAccessor`) provides permission to access the value of a secret.
*   **Granting Permission:** This is typically done when configuring the service account for each Cloud Run service.
    *   **Via GCP Console (IAM Page or Secret Manager UI):**
        1.  Go to the Secret Manager page and select your secret.
        2.  In the permissions panel on the right, click "Add Principal".
        3.  Enter the email address of the service account associated with your Cloud Run service.
        4.  Assign the "Secret Manager Secret Accessor" role.
        5.  Click "Save".
    *   **Via `gcloud` CLI:**
        ```bash
        gcloud secrets add-iam-policy-binding SECRET_NAME \
            --member="serviceAccount:CLOUD_RUN_SERVICE_ACCOUNT_EMAIL" \
            --role="roles/secretmanager.secretAccessor"
        ```
        Replace `SECRET_NAME` with the name of your secret and `CLOUD_RUN_SERVICE_ACCOUNT_EMAIL` with the email of the service account used by the Cloud Run service.

This process will be repeated for each service and each secret it needs to access. Detailed service account setup for Cloud Run services will be covered in a later section.

### 5.3. Exposing Secrets as Environment Variables in Cloud Run

Cloud Run allows you to securely expose secrets stored in Secret Manager as environment variables to your running service instances. The actual secret value is never stored in the Cloud Run service definition or visible in plain text in the environment variable configuration.

**Configuration:**

When deploying a Cloud Run service, you can map secrets to environment variables:

*   **Via GCP Console:**
    When creating or updating a Cloud Run service, under the "Variables & Secrets" tab (or similar wording), in the "Secrets" section:
    1.  Click "Add Secret" or "Reference a secret".
    2.  Choose the **Secret name** from Secret Manager.
    3.  Choose the **Version** (e.g., `latest`).
    4.  Specify the **Environment variable name** that your application code expects (e.g., `POSTGRES_PASSWORD`).
    5.  Select how it should be exposed (e.g., "Exposed as environment variable").

*   **Via `gcloud run deploy` command:**
    Use the `--set-secrets` flag:
    ```bash
    gcloud run deploy YOUR_SERVICE_NAME \
        --image YOUR_IMAGE_URI \
        --region YOUR_REGION \
        --service-account YOUR_CLOUD_RUN_SERVICE_ACCOUNT_EMAIL \
        --set-secrets=[ENV_VAR_NAME_1=secret-name-1:version],[ENV_VAR_NAME_2=secret-name-2:version] \
        # ... other flags
    ```
    **Example:**
    ```bash
    gcloud run deploy api-gateway-service \
        --image gcr.io/YOUR_PROJECT_ID/api-gateway:latest \
        --region us-central1 \
        --service-account api-gateway-sa@YOUR_PROJECT_ID.iam.gserviceaccount.com \
        --set-secrets=[POSTGRES_PASSWORD=aethercast-db-password:latest,FLASK_SECRET_KEY=aethercast-flask-secret-key:latest,GCS_BUCKET_NAME=aethercast-gcs-bucket-name:latest] \
        --allow-unauthenticated # If it's a public-facing service like API Gateway
    ```

**Benefits:**
-   Actual secret values are not stored in your service configuration or source code.
-   Access to secrets is controlled by IAM.
-   Your application code can continue to read configuration from environment variables as it likely does for local development (e.g., using values from `.env` files). The environment variable names set in Cloud Run (e.g., `POSTGRES_PASSWORD`) should match what the application expects (as typically defined in the service's `.env.example` file).

This approach ensures that sensitive data is handled securely throughout your deployment.

## 6. Containerization and Artifact Registry

Each Aethercast microservice is designed to run in its own Docker container. Before deploying these services to Cloud Run, their container images must be built and stored in a container registry. Google Artifact Registry is the recommended service for storing and managing container images on GCP.

### 6.1. Reviewing Dockerfiles

Each service in the `aethercast/` directory (e.g., `api_gateway/`, `aims_service/`, etc.) contains a `Dockerfile` that defines how its container image is built. Before deploying to GCP, it's good practice to review these Dockerfiles.

**General Advice for Production Dockerfiles:**

*   **Optimization:** Ensure Dockerfiles are reasonably optimized. This includes using multi-stage builds where appropriate to reduce image size, minimizing layers, and cleaning up build artifacts.
*   **Specific Base Images:** Use official and specific base image tags (e.g., `python:3.9-slim` instead of `python:latest`) for better reproducibility and security.
*   **Non-Root User:** If not already implemented, consider running applications as a non-root user inside the container for improved security. (This might require changes to file permissions and listening on ports > 1024).

**GCP Cloud Run Context:**

*   **Volume Mounts:** Local Docker Compose configurations might use host-mounted volumes (e.g., for credentials or shared data). These direct host mounts are not applicable to Cloud Run. Secret management (covered in Section 5) and GCS integrations are the cloud-native ways to handle external data and configuration. Cloud Run does support mounting GCS buckets as volumes if needed for specific use cases, which is different from local Docker volume mounts.
*   **Application Startup (`CMD`/`ENTRYPOINT`):**
    *   Ensure the `CMD` or `ENTRYPOINT` in each Dockerfile correctly starts the application.
        *   **Flask Apps (API Gateway, TDA/SCA/PSWA/IGA/VFA services):** Use a production WSGI server like `gunicorn`. Example: `CMD ["gunicorn", "--bind", "0.0.0.0:8080", "main:app"]` (port will be overridden by Cloud Run's `PORT` env var).
        *   **Celery Workers (TDA/SCA/PSWA/IGA/VFA workers):** The `CMD` should start the Celery worker process. Example: `CMD ["celery", "-A", "main.celery_app", "worker", "-l", "info"]`. You might need separate Dockerfiles or use a startup script if the same image is used for both app server and worker. Often, it's cleaner to have slightly different Docker images or use command overrides in Cloud Run service definitions if the base image is the same.
*   **Listening Port (for Flask Apps):**
    *   Applications running in Cloud Run must listen for incoming requests on `0.0.0.0`.
    *   Cloud Run automatically provides a `PORT` environment variable (typically `8080`) that your application should listen on. The `gunicorn` command above should bind to this port. If your application code or startup script hardcodes a port, it needs to be updated to use the `PORT` environment variable.
    *   Many of the Aethercast services' `main.py` or Dockerfiles might already be configured to use `os.environ.get("PORT", <default_local_port>)` or similar, which is good. Ensure the Docker `CMD` ultimately respects the `PORT` variable set by Cloud Run.

### 6.2. Setting up Artifact Registry

Artifact Registry is where you'll store your Docker images.

1.  **Create a Docker Repository:**
    You need to create a Docker repository in Artifact Registry within your chosen region.
    *   **Via GCP Console:**
        1.  Navigate to [Artifact Registry](https://console.cloud.google.com/artifacts) in the GCP Console.
        2.  Click "Create Repository".
        3.  Enter a **Name** (e.g., `aethercast-services`).
        4.  Select **Format** as "Docker".
        5.  Choose the **Region** where you want to store your images (ideally the same region as your Cloud Run services, e.g., `us-central1`).
        6.  Click "Create".
    *   **Via `gcloud` CLI:**
        ```bash
        gcloud artifacts repositories create aethercast-services \
            --repository-format=docker \
            --location=YOUR_CHOSEN_REGION \
            --description="Docker images for Aethercast services"
        ```
        Replace `YOUR_CHOSEN_REGION` with your GCP region (e.g., `us-central1`).

2.  **Configure Docker Authentication:**
    Configure your local Docker client to authenticate with Artifact Registry:
    ```bash
    gcloud auth configure-docker YOUR_CHOSEN_REGION-docker.pkg.dev
    ```
    For example, if your region is `us-central1`, the command would be:
    `gcloud auth configure-docker us-central1-docker.pkg.dev`

### 6.3. Building and Pushing Images

You can build your images locally and push them, or use Cloud Build for a more automated approach. The image name format for Artifact Registry is `REGION-docker.pkg.dev/PROJECT_ID/REPOSITORY_NAME/IMAGE_NAME:TAG`.

#### 6.3.1. Building Locally and Pushing

This method is suitable for initial testing or smaller projects. Repeat these steps for each Aethercast service (e.g., `api_gateway`, `tda`, `aims_service`, etc.).

1.  **Navigate to the service directory:**
    For example, for the API Gateway:
    ```bash
    cd aethercast/api_gateway
    ```
2.  **Build and Tag the image:**
    Replace `YOUR_CHOSEN_REGION`, `YOUR_PROJECT_ID`, and `SERVICE_NAME` accordingly.
    ```bash
    docker build . -t YOUR_CHOSEN_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/api-gateway:latest
    ```
    (For `aims_service`, the `SERVICE_NAME` would be `aims-service`, and so on).
3.  **Push the image:**
    ```bash
    docker push YOUR_CHOSEN_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/api-gateway:latest
    ```

You would do this for all services: `api-gateway`, `cpoa` (if it becomes separate), `tda`, `sca`, `pswa`, `vfa`, `asf`, `aims-service`, `aims-tts-service`, `iga`.

#### 6.3.2. Building with Cloud Build (Recommended)

Cloud Build can build your Docker images directly from your source code (either uploaded from your local machine or from a connected Git repository) and push them to Artifact Registry. This is more robust and integrates well with CI/CD pipelines.

Each Aethercast service directory already contains a `Dockerfile`.

1.  **Submit a build from your local source code:**
    Navigate to the specific service directory (e.g., `cd aethercast/api_gateway`) and run:
    ```bash
    gcloud builds submit . --tag YOUR_CHOSEN_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/api-gateway:latest
    ```
    Replace `YOUR_CHOSEN_REGION`, `YOUR_PROJECT_ID`, and use the appropriate service name (e.g., `aims-service`, `tda`). Cloud Build will upload the contents of the current directory (respecting `.gcloudignore`) as the build context.

    You would repeat this for each service.

2.  **Automated Triggers (for CI/CD):**
    Cloud Build can also be configured with triggers to automatically build and push images when changes are pushed to a connected Git repository (e.g., Cloud Source Repositories, GitHub, Bitbucket). This is a key part of a CI/CD pipeline and will be discussed conceptually in a later section.

**Note on Image Tagging:**
While `latest` is convenient for development, for production deployments, it's highly recommended to use more specific and immutable tags, such as:
-   Git commit SHA (e.g., `gcloud builds submit . --tag .../api-gateway:$(git rev-parse --short HEAD)`)
-   Semantic version numbers (e.g., `v1.0.1`)

This ensures that your deployments are predictable and you can roll back to specific versions if needed.

## 7. Deploying Services to Cloud Run

Google Cloud Run is a managed compute platform that enables you to run stateless containers that are invocable via web requests or Pub/Sub events. It's well-suited for deploying the Aethercast microservices. We will deploy each service as a separate Cloud Run service.

The Aethercast services to be deployed include:
-   API Gateway (`api_gateway`)
-   AIMS Service (`aims_service`)
-   AIMS TTS Service (`aims_tts_service`)
-   Audio Stream Feeder (`asf`)
-   Image Generation Agent (`iga`)
-   Podcast Script Weaver Agent (`pswa`)
-   Snippet Craft Agent (`sca`)
-   Topic Discovery Agent (`tda`)
-   Voice Forge Agent (`vfa`)

*(Note: The Central Podcast Orchestrator (CPOA) is currently integrated within the API Gateway process. If it were a separate service, it would be deployed similarly.)*

### 7.1. General Deployment Principles & Parameters

We will primarily use the `gcloud run deploy` command to deploy services. The general structure is:

```bash
gcloud run deploy [SERVICE_NAME] \
    --image=[IMAGE_URL] \
    --platform=managed \
    --region=[REGION] \
    # --- Ingress & Authentication ---
    --allow-unauthenticated \ # Or --no-allow-unauthenticated for internal services
    --ingress=[all|internal|internal-and-cloud-load-balancing] \
    --service-account=[SERVICE_ACCOUNT_EMAIL] \
    # --- Scaling & Performance ---
    --cpu=[CPU_COUNT] \
    --memory=[MEMORY_SIZE] \
    --concurrency=[CONCURRENCY_COUNT] \
    --min-instances=[MIN_INSTANCES] \
    --max-instances=[MAX_INSTANCES] \
    # --- Environment & Secrets ---
    --set-env-vars=[KEY1=VALUE1,KEY2=VALUE2] \
    --set-secrets=[ENV_VAR_NAME1=secret-name1:version,ENV_VAR_NAME2=secret-name2:version] \
    # --- Networking & Database ---
    --vpc-connector=[VPC_CONNECTOR_NAME] \ # If needed for Private IP access
    --add-cloudsql-instances=[CLOUDSQL_INSTANCE_CONNECTION_NAME] # For Cloud SQL Auth Proxy
    # ... other flags
```

Key parameters explained:

*   **Service Naming (`[SERVICE_NAME]`):** Use a consistent naming convention for your Cloud Run services.
    *   Example: `aethercast-api-gateway`, `aethercast-aims-service`, `aethercast-tda`.
*   **Image URL (`--image`):** This is the full path to your container image in Artifact Registry.
    *   Format: `YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/SERVICE_IMAGE_NAME:TAG`
    *   Example: `us-central1-docker.pkg.dev/my-aethercast-project/aethercast-services/api-gateway:latest`
*   **Region (`--region`):** The GCP region where the service will be deployed. This should be the same region used for Artifact Registry, Cloud SQL, and other related resources to minimize latency and cost.
*   **Platform (`--platform`):** Set to `managed` for the serverless Cloud Run environment.
*   **CPU and Memory (`--cpu`, `--memory`):**
    *   Specify the amount of CPU and memory allocated to each instance of your service.
    *   Start with smaller allocations (e.g., `--cpu=1`, `--memory=512Mi`) and monitor performance to adjust as needed. Some services might need more based on their workload (e.g., AI model inference).
*   **Concurrency (`--concurrency`):**
    *   The maximum number of concurrent requests that a single container instance can handle. The default is 80.
    *   Adjust based on whether your application is CPU-bound or I/O-bound.
*   **Autoscaling (`--min-instances`, `--max-instances`):**
    *   `--min-instances`: Set to `0` for development/testing to save costs (service scales to zero when idle). For production, you might set a minimum of `1` or more to reduce cold starts for frequently accessed services.
    *   `--max-instances`: The maximum number of instances Cloud Run can scale out to.
*   **Port Configuration:** Cloud Run automatically injects a `PORT` environment variable (usually `8080`). Your application inside the container must listen on `0.0.0.0` and this `PORT`. The Dockerfiles for Aethercast services (using Gunicorn) should already be configured for this. No explicit `--port` flag is usually needed for `gcloud run deploy` unless your container listens on a different port than what `PORT` provides.
*   **Environment Variables:**
    *   `--set-env-vars`: For non-sensitive configuration (e.g., `FLASK_DEBUG=False`, `AIMS_GOOGLE_LLM_MODEL_ID=gemini-pro`).
    *   `--set-secrets`: For sensitive data. This links an environment variable in your Cloud Run service to a secret stored in Google Secret Manager.
        *   Format: `[ENV_VAR_NAME=secret-name:version]` e.g., `POSTGRES_PASSWORD=aethercast-db-password:latest`.
*   **Service Account (`--service-account`):**
    *   Each Cloud Run service should run with a dedicated IAM Service Account. This follows the principle of least privilege.
    *   You will create these service accounts and grant them only the necessary IAM roles (e.g., Secret Manager Secret Accessor, Cloud SQL Client, Vertex AI User, Storage Object Admin/Creator/Viewer).
    *   Example: `sa-aethercast-aims@YOUR_PROJECT_ID.iam.gserviceaccount.com`.
*   **Connectivity / Networking:**
    *   **Ingress Control (`--ingress`):** Controls how your service is reached.
        *   `all`: Allows all traffic from the internet (suitable for the public-facing API Gateway).
        *   `internal`: Only allows traffic from within your GCP project (VPC network, other Cloud Run services, etc.).
        *   `internal-and-cloud-load-balancing`: Allows internal traffic and traffic from Google Cloud Load Balancing.
        *   Backend services (AIMS, TDA, etc.) should typically use `internal`.
    *   **VPC Connector (`--vpc-connector`):**
        *   If your service needs to access resources within your VPC network (like a Cloud SQL instance using Private IP), it needs a Serverless VPC Access connector.
        *   You create a connector in the VPC Network settings page in GCP Console, and then reference it here by its fully qualified name.
    *   **Cloud SQL Connection (`--add-cloudsql-instances`):**
        *   This flag simplifies connecting to Cloud SQL instances, especially when using the Cloud SQL Auth Proxy. Provide the full instance connection name (e.g., `YOUR_PROJECT_ID:YOUR_REGION:YOUR_CLOUDSQL_INSTANCE_ID`).
        *   Cloud Run will make a Unix domain socket available to your service for connecting to the database.

### 7.2. Deploying Backend AI Services

These services are typically internal, invoked by other Aethercast services (like CPOA, which runs within the API Gateway). They should have internal ingress settings.

#### 7.2.1. Deploying `aims_service`

**Purpose:** Provides access to Large Language Models (LLMs) via Vertex AI.

**1. Create Service Account:**
   - Name: `sa-aethercast-aims`
   - Email: `sa-aethercast-aims@YOUR_PROJECT_ID.iam.gserviceaccount.com`
   - Required IAM Roles:
     - `Vertex AI User` (roles/aiplatform.user): To make predictions using Vertex AI models.
     - `Secret Manager Secret Accessor` (roles/secretmanager.secretAccessor): To access secrets like GCP Project ID and Location if stored in Secret Manager.
     ```bash
     # Create Service Account
     gcloud iam service-accounts create sa-aethercast-aims --display-name="Aethercast AIMS Service Account"

     # Grant roles (replace YOUR_PROJECT_ID)
     gcloud projects add-iam-policy-binding YOUR_PROJECT_ID --member="serviceAccount:sa-aethercast-aims@YOUR_PROJECT_ID.iam.gserviceaccount.com" --role="roles/aiplatform.user"
     # Grant access to specific secrets as shown in Section 5.2
     ```

**2. Deploy to Cloud Run:**
```bash
gcloud run deploy aethercast-aims-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/aims-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-aims@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --set-env-vars=FLASK_DEBUG=False,AIMS_GOOGLE_LLM_MODEL_ID=gemini-1.0-pro,CELERY_BROKER_URL=YOUR_REDIS_URL,CELERY_RESULT_BACKEND=YOUR_REDIS_URL \
    --set-secrets="GCP_PROJECT_ID=aethercast-gcp-project-id:latest,GCP_LOCATION=aethercast-gcp-location:latest" \
    --cpu=1 \
    --memory=512Mi \
    --concurrency=80 \
    --min-instances=0 \
    --max-instances=2 # Adjust as needed
```
*Replace `YOUR_REGION`, `YOUR_PROJECT_ID`, and `YOUR_REDIS_URL` (which might come from a Secret if it contains a password, or be the internal DNS for a Memorystore Redis instance).*
*Ensure the secret names `aethercast-gcp-project-id` and `aethercast-gcp-location` exist in Secret Manager.*
*Note: AIMS Service itself is synchronous; Celery env vars are listed if it were to ever use Celery internally for some sub-processing, but it's not its primary mode.*


#### 7.2.2. Deploying `aims_tts_service`

**Purpose:** Handles Text-to-Speech via Google Cloud TTS (now via an internal Celery task), saves audio to GCS.

**1. Create Service Account:** (As before, ensure Vertex AI User or Cloud Text-to-Speech User, Storage Object Creator, Secret Manager Secret Accessor)

**2. Deploy App Service (`aethercast-aims-tts-service`):**
   This service will receive HTTP requests and dispatch Celery tasks.
```bash
gcloud run deploy aethercast-aims-tts-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/aims-tts-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-aims-tts@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \ # For Idempotency
    --set-env-vars=FLASK_DEBUG=False,AIMS_TTS_GCS_AUDIO_PREFIX=audio/aims_tts/,AIMS_TTS_DEFAULT_VOICE_ID=en-US-Wavenet-D,AIMS_TTS_DEFAULT_LANGUAGE_CODE=en-US,AIMS_TTS_DEFAULT_AUDIO_ENCODING_STR=MP3 \
    --set-secrets="GCP_PROJECT_ID=aethercast-gcp-project-id:latest,GCP_LOCATION=aethercast-gcp-location:latest,GCS_BUCKET_NAME=aethercast-gcs-bucket-name:latest,POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 \
    --memory=512Mi \
    --concurrency=80 \
    --min-instances=0 \
    --max-instances=3
```
**3. Deploy Worker Service (`aethercast-aims-tts-worker`):**
   This service runs the Celery worker for `aims_tts_service`.
```bash
gcloud run deploy aethercast-aims-tts-worker \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/aims-tts-service:latest \ # Often uses the same image
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-aims-tts@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --no-traffics \ # Worker typically doesn't serve HTTP traffic directly
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \ # For Idempotency
    --set-env-vars=FLASK_DEBUG=False,AIMS_TTS_GCS_AUDIO_PREFIX=audio/aims_tts/,IS_CELERY_WORKER=True \ # Add IS_CELERY_WORKER
    --set-secrets="GCP_PROJECT_ID=aethercast-gcp-project-id:latest,GCP_LOCATION=aethercast-gcp-location:latest,GCS_BUCKET_NAME=aethercast-gcs-bucket-name:latest,POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --command=celery \ # Override CMD to start worker
    --args="-A,main.celery_app,worker,-l,info" \
    --cpu=1 \
    --memory=1Gi # Workers might need more memory for TTS
    --min-instances=0 \ # Can be 0 for dev/test, or 1+ for prod
    --max-instances=5
```

#### 7.2.3. Deploying `iga_service` (App and Worker)

**Purpose:** Generates images using Vertex AI Imagen (via Celery task) and saves them to GCS.

**1. Create Service Account:** (As before: Vertex AI User, Storage Object Creator, Secret Manager Secret Accessor, Cloud SQL Client for idempotency)

**2. Deploy App Service (`aethercast-iga-service`):**
```bash
gcloud run deploy aethercast-iga-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/iga-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-iga@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,IGA_GCS_IMAGE_PREFIX=images/iga/,IGA_VERTEXAI_IMAGE_MODEL_ID=imagegeneration@006 \
    --set-secrets="GCP_PROJECT_ID=aethercast-gcp-project-id:latest,GCP_LOCATION=aethercast-gcp-location:latest,GCS_BUCKET_NAME=aethercast-gcs-bucket-name:latest,POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=3
```
**3. Deploy Worker Service (`aethercast-iga-worker`):**
```bash
gcloud run deploy aethercast-iga-worker \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/iga-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-iga@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --no-traffic \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,IGA_GCS_IMAGE_PREFIX=images/iga/,IS_CELERY_WORKER=True \
    --set-secrets="GCP_PROJECT_ID=aethercast-gcp-project-id:latest,GCP_LOCATION=aethercast-gcp-location:latest,GCS_BUCKET_NAME=aethercast-gcs-bucket-name:latest,POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --command=celery --args="-A,main.celery_app,worker,-l,info" \
    --cpu=1 --memory=1Gi --min-instances=0 --max-instances=5
```

### 7.3. Deploying Core Content and Orchestration Services (App and Worker for each)

These services (TDA, SCA, PSWA, VFA) now all follow a similar pattern: a Flask app service for API interactions (task dispatching, status polling) and a Celery worker service for background processing. Both need access to PostgreSQL for idempotency (and potentially other data) and Celery broker (Redis).

#### 7.3.1. Deploying `tda_service` (App and Worker)

**Purpose:** Topic Discovery Agent (Celery-based), uses NewsAPI, stores topics in PostgreSQL.

**1. Create Service Account:** (As before: Cloud SQL Client, Secret Manager Secret Accessor for DB & NewsAPI key)

**2. Deploy App Service (`aethercast-tda-service`):**
```bash
gcloud run deploy aethercast-tda-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/tda-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-tda@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,USE_REAL_NEWS_API=True \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,TDA_NEWS_API_KEY=aethercast-tda-news-api-key:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=2
```
**3. Deploy Worker Service (`aethercast-tda-worker`):**
```bash
gcloud run deploy aethercast-tda-worker \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/tda-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-tda@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --no-traffic \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,USE_REAL_NEWS_API=True,IS_CELERY_WORKER=True \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,TDA_NEWS_API_KEY=aethercast-tda-news-api-key:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --command=celery --args="-A,main.celery_app,worker,-l,info" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=3
```

#### 7.3.2. Deploying `sca_service` (App and Worker)

**Purpose:** Snippet Craft Agent (Celery-based), calls `aims_service`.

**1. Create Service Account:** (As before: Secret Manager Accessor, Cloud Run Invoker for AIMS, Cloud SQL Client for idempotency)

**2. Deploy App Service (`aethercast-sca-service`):**
```bash
# AIMS_SERVICE_INTERNAL_URL should be set from deployed aims-service
gcloud run deploy aethercast-sca-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/sca-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-sca@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,USE_REAL_LLM_SERVICE=True,AIMS_SERVICE_URL=$AIMS_SERVICE_INTERNAL_URL \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=2
```
**3. Deploy Worker Service (`aethercast-sca-worker`):**
```bash
gcloud run deploy aethercast-sca-worker \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/sca-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-sca@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --no-traffic \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,USE_REAL_LLM_SERVICE=True,AIMS_SERVICE_URL=$AIMS_SERVICE_INTERNAL_URL,IS_CELERY_WORKER=True \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --command=celery --args="-A,main.celery_app,worker,-l,info" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=3
```

#### 7.3.3. Deploying `pswa_service` (App and Worker)

**Purpose:** Podcast Script Weaver Agent (Celery-based), calls `aims_service`, uses DB for cache & idempotency.

**1. Create Service Account:** (As before: Cloud SQL Client, Secret Manager Accessor, Cloud Run Invoker for AIMS)

**2. Deploy App Service (`aethercast-pswa-service`):**
```bash
gcloud run deploy aethercast-pswa-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/pswa-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-pswa@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,DATABASE_TYPE=postgres,PSWA_SCRIPT_CACHE_ENABLED=True,AIMS_SERVICE_URL=$AIMS_SERVICE_INTERNAL_URL,PSWA_TEST_MODE_ENABLED=False \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=2
```
**3. Deploy Worker Service (`aethercast-pswa-worker`):**
```bash
gcloud run deploy aethercast-pswa-worker \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/pswa-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-pswa@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --no-traffic \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,DATABASE_TYPE=postgres,PSWA_SCRIPT_CACHE_ENABLED=True,AIMS_SERVICE_URL=$AIMS_SERVICE_INTERNAL_URL,PSWA_TEST_MODE_ENABLED=False,IS_CELERY_WORKER=True \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --command=celery --args="-A,main.pswa_celery_app,worker,-l,info" \
    --cpu=1 --memory=1Gi --min-instances=0 --max-instances=3
```

#### 7.3.4. Deploying `vfa_service` (App and Worker)

**Purpose:** Voice Forge Agent (Celery-based), calls `aims_tts_service`.

**1. Create Service Account:** (As before: Secret Manager Accessor, Cloud Run Invoker for AIMS_TTS, Cloud SQL Client for idempotency)

**2. Deploy App Service (`aethercast-vfa-service`):**
```bash
gcloud run deploy aethercast-vfa-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/vfa-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-vfa@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,VFA_TEST_MODE_ENABLED=False,AIMS_TTS_SERVICE_URL=$AIMS_TTS_SERVICE_INTERNAL_URL \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 --memory=512Mi --min-instances=0 --max-instances=2
```
**3. Deploy Worker Service (`aethercast-vfa-worker`):**
```bash
gcloud run deploy aethercast-vfa-worker \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/vfa-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-vfa@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --no-traffic \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,VFA_TEST_MODE_ENABLED=False,AIMS_TTS_SERVICE_URL=$AIMS_TTS_SERVICE_INTERNAL_URL,IS_CELERY_WORKER=True \
    --set-secrets="POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --command=celery --args="-A,main.celery_app,worker,-l,info" \
    --cpu=1 --memory=1Gi --min-instances=0 --max-instances=3
```

#### 7.3.5. Deploying `asf_service`

**Purpose:** Audio Stream Feeder (WebSocket service). Does not use Celery itself.

**1. Create Service Account:** (As before: Secret Manager Accessor, Cloud Run Invoker for API GW for signed URLs)

**2. Deploy to Cloud Run:** (As before, ensure `INTERNAL_API_GW_BASE_URL` is set to the deployed API Gateway's internal URL)
```bash
# Example: API_GATEWAY_INTERNAL_URL=$(gcloud run services describe aethercast-api-gateway --platform managed --region YOUR_REGION --format 'value(status.url)')
# Example: FRONTEND_URL="https://your-frontend-or-api-gateway-url.a.run.app"

gcloud run deploy aethercast-asf-service \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/asf-service:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-asf@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=internal \
    --session-affinity \
    --set-env-vars=FLASK_DEBUG=False,INTERNAL_API_GW_BASE_URL=$API_GATEWAY_INTERNAL_URL,ASF_CORS_ALLOWED_ORIGINS=$FRONTEND_URL \
    --set-secrets="FLASK_SECRET_KEY=aethercast-flask-secret-key:latest" \
    --cpu=1 --memory=512Mi --concurrency=80 --min-instances=0 --max-instances=2
```

### 7.4. Deploying the API Gateway Service

(No significant changes here other than ensuring the backend service URLs passed as env vars are the new Cloud Run URLs for the *app services* of TDA, PSWA, etc., not their workers). The `api-gateway-service` itself doesn't run a Celery worker. Its CPOA logic dispatches tasks to other services' Celery queues.

#### 7.4.1. Deploying `api-gateway-service`

**1. Create Service Account:** (As before: Cloud SQL Client, Secret Manager Accessor, SA Token Creator for GCS URLs, Cloud Run Invoker for all backend app services TDA, PSWA, SCA, VFA, IGA, ASF).

**2. Deploy to Cloud Run:**
```bash
# Gather internal URLs for all backend services (TDA_URL, PSWA_URL, etc.)
# Example: TDA_APP_URL=$(gcloud run services describe aethercast-tda-service --platform managed --region YOUR_REGION --format 'value(status.url)')
# ... and so on for SCA_APP_URL, PSWA_APP_URL, VFA_APP_URL, IGA_APP_URL, ASF_APP_URL

gcloud run deploy aethercast-api-gateway \
    --image=YOUR_REGION-docker.pkg.dev/YOUR_PROJECT_ID/aethercast-services/api-gateway:latest \
    --platform=managed \
    --region=YOUR_REGION \
    --service-account=sa-aethercast-api-gateway@YOUR_PROJECT_ID.iam.gserviceaccount.com \
    --ingress=all \
    --allow-unauthenticated \
    --add-cloudsql-instances=YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance \
    --set-env-vars=FLASK_DEBUG=False,DATABASE_TYPE=postgres,TDA_SERVICE_URL=$TDA_APP_URL,PSWA_SERVICE_URL=$PSWA_APP_URL,VFA_SERVICE_URL=$VFA_APP_URL,SCA_SERVICE_URL=$SCA_APP_URL,IGA_SERVICE_URL=$IGA_APP_URL,ASF_NOTIFICATION_URL=$ASF_APP_URL/asf/internal/notify_new_audio,CPOA_ASF_SEND_UI_UPDATE_URL=$ASF_APP_URL/asf/internal/send_ui_update,ASF_WEBSOCKET_BASE_URL=ws_or_wss_url_for_asf \
    --set-secrets="FLASK_SECRET_KEY=aethercast-flask-secret-key:latest,POSTGRES_HOST=/cloudsql/YOUR_PROJECT_ID:YOUR_REGION:aethercast-postgres-instance,POSTGRES_PORT=5432,POSTGRES_USER=aethercast-pg-user:latest,POSTGRES_PASSWORD=aethercast-pg-password:latest,POSTGRES_DB=aethercast-pg-db:latest,GCS_BUCKET_NAME=aethercast-gcs-bucket-name:latest,CELERY_BROKER_URL=aethercast-celery-broker-url:latest,CELERY_RESULT_BACKEND=aethercast-celery-result-backend-url:latest" \
    --cpu=1 --memory=1Gi --concurrency=80 --min-instances=0 --max-instances=5
```

## 8. Inter-Service Communication in Cloud Run
(No changes seem immediately necessary in sections 8.1 to 8.4 due to idempotency itself, but the context is now Celery tasks for many backend services).

## 9. Authentication and Authorization (IAM for Cloud Run Services)
(No changes seem immediately necessary here, but service accounts for workers will need appropriate DB access like their app counterparts).

## 10. Frontend Deployment
(No changes seem immediately necessary here).

## 11. Accessing the Application
(No changes seem immediately necessary here).

## 12. Logging and Monitoring
(No changes seem immediately necessary here, but logs from worker services should also be monitored).

## 13. CI/CD Pipeline (Conceptual Outline)

1.  **Source Control Repository:** (As before)
2.  **Cloud Build Triggers:** (As before)
3.  **Build Stage (Cloud Build using `cloudbuild.yaml`):**
    *   **For each Aethercast microservice (App and potentially Worker if separate images):**
        *   (As before) Build and push Docker image(s) to Artifact Registry.
4.  **Deploy Stage (Cloud Build using `cloudbuild.yaml`):**
    *   **Database Migrations:** Add a step to run database migrations **before** deploying services that depend on the new schema. This must include the `001_create_idempotency_keys_table.sql` migration.
        ```yaml
        # Example step for DB migration (using a utility container or Cloud SQL proxy)
        # - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
        #   entrypoint: 'bash'
        #   args:
        #     - '-c'
        #     - |
        #       # Setup Cloud SQL Proxy
        #       # wget https://storage.googleapis.com/cloudsql-proxy/v1.28.0/cloud_sql_proxy.linux.amd64 -O cloud_sql_proxy
        #       # chmod +x cloud_sql_proxy
        #       # ./cloud_sql_proxy -instances=${_CLOUDSQL_INSTANCE_CONNECTION_NAME}=tcp:5432 &
        #       # sleep 5 # Wait for proxy
        #       # PGPASSWORD=$(gcloud secrets versions access latest --secret=aethercast-db-password) psql -h 127.0.0.1 -U $(gcloud secrets versions access latest --secret=aethercast-db-user) -d $(gcloud secrets versions access latest --secret=aethercast-db-name) -f aethercast/data_stores/migrations/001_create_idempotency_keys_table.sql
        #       # Add similar commands for other DDLs if not handled by app startup (e.g. TDA's init_tda_db)
        ```
    *   Deploy App services (api-gateway, tda-service, sca-service, etc.) to Cloud Run.
    *   Deploy Worker services (tda-worker, sca-worker, etc.) to Cloud Run, possibly with different command overrides.
    *   Frontend Deployment: (As before)

**Benefits:** (As before)

## 14. Cost Considerations
(No major changes, but acknowledge potential costs of Redis if used for Celery at scale).

## 15. Cleanup
(Add Celery worker services to the list of Cloud Run services to delete).

---

*For information on the overarching Aethercast project architecture, advanced setup including database migrations for shared resources like idempotency tables, and how services interact, please refer to the main [README.md](../../../README.md) at the root of the Aethercast project.*
