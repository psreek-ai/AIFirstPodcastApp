# OPENAI_API_KEY: Your API key for OpenAI. (Required)
OPENAI_API_KEY=your_openai_api_key_here

# PSWA_LLM_MODEL: The OpenAI model ID to use for script generation.
# Models like gpt-3.5-turbo-1106, gpt-4-1106-preview, gpt-3.5-turbo-0125, or gpt-4-turbo-preview support JSON mode.
PSWA_LLM_MODEL=gpt-3.5-turbo-0125

# PSWA_LLM_TEMPERATURE: Temperature for the LLM response (0.0 to 2.0).
PSWA_LLM_TEMPERATURE=0.7

# PSWA_LLM_MAX_TOKENS: Maximum tokens to generate in the LLM response.
PSWA_LLM_MAX_TOKENS=1500

# PSWA_LLM_JSON_MODE: Set to 'true' to request JSON output from compatible LLMs.
# If 'true', ensure system/user prompts guide the LLM for JSON output.
# If 'false' or if the model doesn't support JSON mode flag, PSWA will rely on tag-based parsing from text.
PSWA_LLM_JSON_MODE=true

# PSWA_DEFAULT_PROMPT_SYSTEM_MESSAGE: System message for the LLM.
# This example is for JSON mode. Adjust if not using JSON mode or for different structures.
PSWA_DEFAULT_PROMPT_SYSTEM_MESSAGE="You are a podcast scriptwriter. Your output MUST be a single, valid JSON object. Do not include any text outside of this JSON object, not even markdown tags like ```json. The JSON object should conform to the following schema: {\"title\": \"string\", \"intro\": \"string\", \"segments\": [{\"segment_title\": \"string\", \"content\": \"string\"}], \"outro\": \"string\"}. If content is insufficient, return JSON: {\"error\": \"Insufficient content\", \"message\": \"Details... for topic: [topic_name_here]\"}."

# PSWA_DEFAULT_PROMPT_USER_TEMPLATE: Template for the user message to the LLM.
# Use {topic} and {content} as placeholders. This example is for JSON mode.
PSWA_DEFAULT_PROMPT_USER_TEMPLATE="Generate a podcast script for topic '{topic}' using the following content:\n---\n{content}\n---\nRemember, your entire response must be a single JSON object conforming to the schema provided in the system message."

# Flask app parameters
PSWA_HOST=0.0.0.0
PSWA_PORT=5004
PSWA_DEBUG=True
